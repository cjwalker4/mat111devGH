---
title: "Confidence Intervals: Pt.1"
author: "Homer White"
date: "April, 2016"
output:
  ioslides_presentation:
    incremental: no
    mathjax: default
    widescreen: yes
    standalone:  true
    css:  slide_styles.css
---

```{r include=FALSE}
library(tigerstats)
```

# From Chance to Confidence


## Before Flip, There are Chances


Say you are about to flip a fair coin.

* It could turn out either Heads or Tails
* $P(\textbf{heads})=0.5$

## After Flip, There is Confidence


Say you have already flipped the coin.  It is hidden in your hand.

* It could be Heads.
* It could be Tails.
* But there are no "chances" left.

Before the coin was flipped, it had a 50% chance to be Heads ...

... NOW you are 50%-*confident* that it is Heads.
  
## Before Sample:  Chances


Suppose you are about take a simple random sample of "big enough" size $n$ from a population.

68-95 Rule for Probability says:

* There is about a 95% chance that $\bar{x}$ will turn out to be within two $SD(\bar{x})$ of $\mu$.
  
This means that:

* There is about a 95% chance that $\mu$ will lie within two $SD(\bar{x})$ of where $\bar{x}$ turns out.
  
## After Sample:  Confidence


After the sampling, $\mu$ either lies within two  $SD(\bar{x})$ or it does not.  (No "chances" left.)

But because of the chance beforehand:

* You are about 95%-confident that $\mu$ lies within two $SD(\bar{x})$ of the $\bar{x}$ that you got.
  
## After Sample:  Confidence

  
Go out on a limb (replace $SD(\bar{x})$ with $SE(\bar{x})$):

* You are about 95%-confident that $\mu$ lies within two $SE(\bar{x})$ of the $\bar{x}$ that you got.
  
(This is part of the 68-95 Rule for Estimation.)



# Intervals for One Mean


## Fastest Speed Ever Driven


```{r eval=FALSE}
data(m111survey)
View(m111survey)
help(m111survey)
```

Focus on variable **fastest**.

Define

  >$\mu =$ mean fastest speed ever driven, for all GC students
  
## Research Question


*On average, how fast do GC students drive, when they drive their fastest?*
  
Note that this question is equivalent to:

* *What is $\mu$?*
  
A confidence interval for $\mu$ will give a range of "reasonable" value of $\mu$, based on the data at hand.


## A Very Good Confidence Interval

We could make rough confidence intervals for $\mu$, using the 68-95 Rule for Estimation.

To get an interval that has closer to the desired level of confidence, we use `ttestGC()`.

*  What is "t"?
*  What's this "test"?

We'll get to that later.  For now, let's just do it!

## ttestGC()


```{r eval = FALSE}
ttestGC(~fastest,data=m111survey)
```

## The Output:  Descriptive


```
Descriptive Results:

 variable  mean    sd  n
  fastest 105.9 20.88 71
```


## The Output:  Inferential


```
Estimate of mu:   105.9 
SE(x.bar):   2.478 
```
You can make your "rough" 95%-confidence interval (68-95 Rule for Estimation):

```{r}
105.9 - 2* 2.478 #the lower bound
105.9+ 2*2.478 #the upper bound
```


## More Inferential Output

A less-rough confidence interval:
```
95% Confidence Interval for mu:

lower.bound         upper.bound          
100.959833          110.842984
```

Not quite the same as the interval from the 68-95 Rule!

## Interpret the Interval!

"we are about 95%-confident that the mean fastest speed at GC is somewhere between 100.96 and 110.84 mph."

## Thought Question
  
* Would it be reasonable for someone to believe, in the face of this data, that $\mu=100$?
* No, because:
    * the confidence interval is the range of values for $\mu$ that are "reasonable", based on the data, and
    * 100 lies outside this interval!

## Other Confidence Levels


Want a 90%-confidence interval?  No problem!

```{r eval=FALSE}
ttestGC(~fastest,data=m111survey,
        conf.level=0.90)
```

We get:

```
90% Confidence Interval for mu:

lower.bound         upper.bound          
101.771329          110.031488 
```


## Confidence Level


* The 90%-confidence interval was not as wide as the 95%-confidence interval
* But we are less confident that $\mu$ lies inside it!

## What "95%-Confident" Means



If you sample repeatedly from the population and make a 95%-confidence interval each time, then

* about 95% of the time, $\mu$ will lie inside your interval
* about 5% of the time, it won't!

(In other words, 95%-confidence interval are designed to be "wrong", 5% of the time!)

## Don't Believe It?


Try this app:  [Intervals for One Mean](http://homer.shinyapps.io/CIMean)


## In Real Life ...


* You take just one sample!
* So you make just one 95%-confidence interval.
* You don't know if $\mu$ lies in the interval or not.
* (But you are 95%-confident that it does!)

## Practice { .practice }

The variable **sleep** in `m111survey` says how many hours of sleep each student got the previous night.

Let $\mu$ be the mean number of hours of sleep that ALL GC students got that night.

Use `ttestGC()` to get a 95% confidence interval for $\mu$.

Many doctors recommended 8 or more hours of sleep.  Based on the data, would it be reasonable to believe that the population of GC students got, on average, the recommended amount that night?  Why or why not?


## A Four-Step Procedure


1. Define the parameter of interest
2. Run the code, and perform a "safety check"
3. Report the confidence interval and interpret it
4. Use the interval to answer your Research Question

## Safety Checks


* Why??  (We'll learn later.)
* They are the same as for the CLT to hold.
* So for confidence interval for one mean $\mu$, just need:
    * random sample from the population, AND
    * a "big enough" sample size
    
## "Big enough?"

$n \ge 30$ is usually big enough, but always check a graph of sample for:

* outliers
* strong skewness

If you don't see these, you are probably OK even at smaller sample sizes.

But there are a lot of really extreme outliers, or very, very strong skewness, then 30 may not be a "big enough" sample size.

Feel free to ask, don't stress too much -- but always check the sample.

## What's REALLY Important ...

... is that the sample was a **random** sample.

The math for behind `ttestGC()` relies on this!

`ttestGC()` results don't apply to samples taken by a biased method like convenience sampling or volunteer sampling!

## Practice { .practice }

Be a good doobie, and check the sample in the previous practice problem:

```{r eval=FALSE}
densityplot(~sleep,data=m111survey,
            main="Sleep Last Night",
            xlab="hours of sleep")
```

The sample size was 71, which is pretty big.  If it had been only 25 and the graph looked like this, do you think it would still be OK to use `ttestGC()` to make a confidence interval for $\mu$?


# Difference of Two Means


## Research Question


  >*Who drives faster, on average:  GC males or GC females?*

## Step One:  Parameters


Let

  >$\mu_1$ = the mean fastest speed of all GC males.

  >$\mu_2$ = the mean fastest speed of all GC females.

We will make a confidence interval for $\mu_1-\mu_2$.

## Step Two (1):  Run Code


First, run the code:

```{r eval=FALSE}
ttestGC(fastest~sex,data=m111survey,
    first="male")
```

(The argument `first` makes R treat populations in the same order you did when you defined the parameters.)


## Step Two (2):  Safety Check



Same as for CLT to hold:

* Need to have taken two independent simple random samples from your two populations
    * (Also OK to have done a completely randomized experiment)
* Both samples sizes must be at least 30
    * (but check graphs of samples, watching out for outliers and strong skewness)
    
## Are We Safe?

    
```
Descriptive Results:

  group  mean    sd  n
   male 113.5 22.57 31
 female 100.0 17.61 40
```

* both sample sizes are big enough
* we (say) that these are like SRS's from the populations

So we are probably safe.

## But It's Always Good ...


... to make graphs of the samples.  Parallel boxplots are nice:

```{r eval=FALSE}
bwplot(fastest~sex,data=m111survey,
       main="Fastest Speed Driven, by Sex",
       xlab="Sex",
       ylab="speed (mph)")
```


## The Boxplots

```{r echo=FALSE}
bwplot(fastest~sex,data=m111survey,
       main="Fastest Speed Driven, by Sex",
       xlab="Sex",
       ylab="speed (mph)")
```

## Step Three (1): Report Interval


Report it:
 
 
```
95% Confidence Interval for mu1-mu2:

lower.bound         upper.bound          
3.548586            23.254640
```

## Step Three(2):  Interpret the Interval


  >Based on the data at hand, we are 95%-confident that $\mu_1-\mu_2$ is somewhere between 3.55 and 23.25 mph.
  
## Step Four:  Conclusion


Use the interval to answer the Research Question:

If GC guys and GC gals drive equally fast on average, then

$$\mu_1-\mu_2 =0$$

* But our confidence interval lies entirely above 0!
* So we can be pretty sure that GC guys drive faster than GC gals, on average.

## Practice { .practice }

Research Question:  Do guys and gals at GC differ in the amount of sleep they get, on average?

Let $\mu_1 = $ mean amount of sleep for all GC females.

Let $\mu_2 = $ mean amount of sleep for all GC males.

Use `ttestGC()` to find a 95%-confidence interval for $\mu_1-\mu_2$.

Do the data allow you to conclude that GC gals get less sleep, average, than guys do?

# Mean of Differences



## The Labels Experiment


```{r eval=FALSE}
data(labels)
View(labels)
help(labels)
```

Research Question:

  >*Will people rate peanut butter more highly, on average, if it comes with a Jiff jar than if it comes in a Great Value jar?*
  
## Descriptive

Make the differences:

```{r}
diff <- with(labels,jiffrating-greatvaluerating)
favstats(diff)
```

## Making a Histogram

```{r eval=FALSE}
histogram(~diff,
  xlab="difference in ratings (jiff - gv)",
  main="Jiff vs. Great Value",
  type="count",
  width=1)
```

---


```{r echo=FALSE}
histogram(~diff,
  xlab="difference in ratings (jiff - gv)",
  main="Jiff vs. Great Value",
  type="count",
  width=1)
```

  
## Inferential Step One:  Define Parameter


Let

  >$\mu_d =$ mean difference in rating (Jiff minus Great Value) for all Georgetown College students
  
Let's make a 95%-confidence interval for $\mu_d$.
  
## Step Two (1):  The Code


```{r eval=FALSE}
ttestGC(~jiffrating-greatvaluerating,
      data=labels)
```

Note the formula:

$$\sim firstNumVar - secondNumVar$$

## Step Two (2):  Safety Check


Same as for CLT to hold:

1. We need to have taken a SRS from the population;
2. Sample size should be at least 30
    *  Remember to check graph of sample for skewness, outliers.
    
## Are We Safe?


1. We hope that the 30 subjects were like a simple random sample from the population.
2. Sample size $n$ is 30.  It's important to check the sample for:
    * signs of strong skewness
    * extreme outliers
    
## Back to that Histogram!


```{r echo=FALSE}
histogram(~diff,xlab="difference in ratings (jiff - gv",
    main="Jiff vs. Great Value",
    type="count",
    breaks=seq(from=-5.5,to=8.5,by=1))
```

## A Judgement Call!


* integer values (not continuous)
* some left-skewness
* maybe an outlier or two at smaller values


These could be a problem at smaller sample sizes, but probably OK here.

## Time Out:  Estimate and SE


```
Estimate of mu-d:   2.367 
SE(d.bar):	 0.513
```

* We got $\bar{d}=2.367$.
* This is more than 4 SEs above 0.
* If labels make no difference ($\mu_d=0$), these results would be very unusual!


## Step Three (1):  Report Interval


95%-confidence interval for $\mu_d$ is:

```
lower         upper          
1.317442      3.415892 
```

## Step Three (2):  Interpret Interval


  >We are 95%-confident that the mean difference in ratings for all GC students (if they could all have been in this experiment), is somewhere between 1.3 and 3.4 points.
  
## Step Four:  Conclusion


* If the label made no difference on average, then $\mu_d$ would be 0.
* But our interval lies above 0.
* So we are pretty sure that GC students would rate Jiff-labeled peanut butter more highly than they rate GV-labeled peanut butter.  (Even though they would tasting the same peanut butter!)

## Practice { .practice }

```{r eval=FALSE}
data(SpiderSpeed)
View(SpiderSpeed)
help(SpiderSpeed)
```

Define $\mu_d$ to be the mean difference in sprinting speeds for ALL Tidarren spiders (after amputation minus before amputation).

Use `ttestGC()` to make a 95%-confidence interval for $\mu_d$.


## Want Less Output?


Sometimes you don't want quite so much output to the console.  To get just the confidence interval:

  >set argument `verbose` to `FALSE`
  
For example:
  
```{r eval=FALSE}
ttestGC(~jiffrating-greatvaluerating,
        data=labels,
        verbose=FALSE)
```

# Handling Summary Data


## Summary From One Sample


Suppose that a random sample of size 36 is taken from a population.  The sample mean is 50 and the sample SD is 4.

  >*Find a 95% confidence interval for $\mu$, the mean of the population.*
  
## The Code and Results


```{r eval=FALSE}
ttestGC(mean=50,sd=4,n=36,
    verbose=FALSE)
```
We get:

```
Inferential Procedures for One Mean mu:
95% Confidence Interval for mu:

lower.bound         upper.bound          
48.646595           51.353405
```

## Summary From Two Samples


Suppose we have taken two indpendent random sample from two populations and we know:


|**Group**|$\bar{x}$|$s$|$n$|
|:----:|:--------:|:-------:|:-----:|
|Group One|45|5|30|
|Group Two|40|6|20|

<br>

Find a 95%-confidence interval for the difference in the means of the two populations.
  
## Code and Results


```{r eval=FALSE}
ttestGC(mean=c(45,40),sd=c(5,6),
    n=c(30,20),verbose=FALSE)
```
We get:

```
Inferential Procedures for the Difference of Two Means mu1-mu2:
  (Welch's Approximation Used for Degrees of Freedom)
	Results from summary data.
95% Confidence Interval for mu1-mu2:

          lower.bound         upper.bound          
          1.707811            8.292189 
```

## Caution

With summary data, you cannot check the samples for outliers and skewness!
